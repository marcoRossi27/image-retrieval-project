# image-retrieval-project
# ğŸš€ Image Retrieval with CLIP and Deep Metric Learning

## Abstract  
This repository presents a modular, end-to-end implementation of an image retrieval system based on a pre-trained CLIP ViT-L/14 backbone, fine-tuned via Deep Metric Learning (DML). Our multi-task training strategy combines ProxyAnchorLoss, TripletMarginLoss with hard-negative mining, and CrossEntropyLoss to learn highly discriminative embeddings. The code supports both the default Food101 dataset and any custom, user-supplied dataset in an ImageFolder format.

---

## ğŸ“‚ Project Structure  
```text
.
â”œâ”€â”€ main.py             # Entrypoint: training & evaluation
â”œâ”€â”€ project_config.py   # Central hyperparameters & paths
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ src/
    â”œâ”€â”€ data/           # Data preparation
    â”‚   â””â”€â”€ datasets.py
    â”œâ”€â”€ transforms/     # Data augmentations
    â”‚   â””â”€â”€ transforms.py
    â”œâ”€â”€ samplers/       # Metric-learning samplers
    â”‚   â””â”€â”€ samplers.py
    â”œâ”€â”€ loader/         # Data loaders
    â”‚   â””â”€â”€ loader.py
    â”œâ”€â”€ models/         # Model definitions
    â”‚   â””â”€â”€ model.py
    â”œâ”€â”€ training/       # Training loop & utilities
    â”‚   â””â”€â”€ trainer.py
    â””â”€â”€ inference/      # Embedding extraction & evaluation
        â””â”€â”€ evaluate.py
```
âš™ï¸ Installation
1. Prerequisites
  - Python 3.8 or higher
  - Git
2. Clone & Virtual Environment
```bash
git clone https://github.com/YOUR_USERNAME/YOUR_REPO.git
cd YOUR_REPO
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```
3. Dependencies
```bash
pip install -r requirements.txt
```
â–¶ï¸ Usage
1. Default Dataset (Food101)
On first execution, the script will download and preprocess Food101 automatically.
```bash
python main.py --mode train
python main.py --mode eval
```
2. Custom Dataset
Your dataset must follow an ImageFolder-style hierarchy:
```bash
your_dataset/
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ class1/
â”‚   â””â”€â”€ class2/
â””â”€â”€ test/
    â”œâ”€â”€ query/
    â””â”€â”€ gallery/
```
Invoke with:
```bash
python main.py --mode train --data_dir /path/to/your_dataset
python main.py --mode eval  --data_dir /path/to/your_dataset
```
ğŸ”§ Configuration
All hyperparameters and paths are centralized in project_config.py. Key parameters include:
Parameter	Description
DEVICE	"cuda" or "cpu"
NUM_CLASSES	Number of classes to sample (default: 100)
MAX_PER_CLASS	Max images per class (default: 250)
BATCH_SIZE	Batch size (default: 32)
LR_BASE / LR_BACKBONE	Learning rates for head and backbone
EPOCHS / WARMUP_EPOCHS	Total and warm-up epochs
EMBED_DIM	Embedding dimensionality (default: 2048)
MARGIN / ALPHA	ProxyAnchor and triplet margins
CE_WEIGHT	Weight for CrossEntropyLoss
dataset_name	"Food101" or "Custom"
Note: Tuning these values is highly recommended for optimal performance on new domains.

