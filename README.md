# image-retrieval-project
#  Image Retrieval with CLIP and Deep Metric Learning

## Abstract  
This repository presents a modular, end-to-end implementation of an image retrieval system based on a pre-trained CLIP ViT-L/14 backbone, fine-tuned via Deep Metric Learning (DML). Our multi-task training strategy combines ProxyAnchorLoss, TripletMarginLoss with hard-negative mining, and CrossEntropyLoss to learn highly discriminative embeddings. The code supports both the default Food101 dataset and any custom, user-supplied dataset in an ImageFolder format.

---

## ðŸ“‚ Project Structure  
```text
.
â”œâ”€â”€ main.py             # Entrypoint: training & evaluation
â”œâ”€â”€ config.py   # Central hyperparameters & paths
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ src/
    â”œâ”€â”€ data/           # Data preparation
    â”‚   â””â”€â”€ datasets.py
    â”œâ”€â”€ transforms/     # Data augmentations
    â”‚   â””â”€â”€ transforms.py
    â”œâ”€â”€ samplers/       # Metric-learning samplers
    â”‚   â””â”€â”€ samplers.py
    â”œâ”€â”€ loader/         # Data loaders
    â”‚   â””â”€â”€ loader.py
    â”œâ”€â”€ models/         # Model definitions
    â”‚   â””â”€â”€ model.py
    â”œâ”€â”€ training/       # Training loop & utilities
    â”‚   â””â”€â”€ trainer.py
    â””â”€â”€ inference/      # Embedding extraction & evaluation
        â””â”€â”€ evaluate.py
```
âš™ï¸ Installation
1. Prerequisites
  - Python 3.8 or higher
  - Git
2. Clone & Virtual Environment
```bash
git clone https://github.com/YOUR_USERNAME/YOUR_REPO.git
cd YOUR_REPO
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```
3. Dependencies
```bash
pip install -r requirements.txt
```
â–¶ï¸ Usage
1. Default Dataset (Food101)
On first execution, the script will download and preprocess Food101 automatically.
```bash
python main.py --mode train
python main.py --mode eval
```
2. Custom Dataset
Your dataset must follow an ImageFolder-style hierarchy:
```bash
your_dataset/
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ class1/
â”‚   â””â”€â”€ class2/
â””â”€â”€ test/
    â”œâ”€â”€ query/
    â””â”€â”€ gallery/
```
Invoke with:
```bash
python main.py --mode train --data_dir /path/to/your_dataset
python main.py --mode eval  --data_dir /path/to/your_dataset
```
ðŸ”§ Configuration
```text
## ðŸ”§ Configuration

All hyperparameters and paths live in `config.py`. You can tweak these to suit your dataset or hardware.

| Parameter             | Description                                                      |
|-----------------------|------------------------------------------------------------------|
| `DEVICE`              | Compute device, either `"cuda"` (GPU) or `"cpu"`.               |
| `NUM_CLASSES`         | Number of classes to sample (default: `100`).                   |
| `MAX_PER_CLASS`       | Maximum images per class (default: `250`).                      |
| `BATCH_SIZE`          | Mini-batch size (default: `32`).                                |
| `LR_BASE` / `LR_BACKBONE` | Learning rates for the MLP head and the CLIP backbone.    |
| `EPOCHS` / `WARMUP_EPOCHS` | Total training epochs and warm-up epochs.              |
| `EMBED_DIM`           | Dimensionality of the embedding vector (default: `2048`).       |
| `MARGIN` / `ALPHA`    | Margin (for triplet loss) and alpha (for ProxyAnchorLoss).      |
| `CE_WEIGHT`           | Weight of the `CrossEntropyLoss` term in the total loss.        |
| `dataset_name`        | `"Food101"` (default) or `"Custom"` (for your own ImageFolder). |

> **Tip:** Experiment with these settings for different domains and compute budgets!  
```
